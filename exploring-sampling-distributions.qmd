---
title: "Exploring sampling distribution concepts"
format: 
  dashboard:
    theme:
      - spacelab
      - custom.scss
server: shiny
---

```{r setup, include = FALSE}
library(tidyverse)
library(latex2exp)
library(shinydashboard)
```

```{r}
#| context: server

source('global.R', local = FALSE)

################################################################################
### REACTIVE OBJECTS
################################################################################

samples <- reactive({
  generate_samples(bowl, size=input$sample_size, reps = input$replications) |> 
    summarise(
      prop_red = sum(colour == "Red")/n()
    )
})

dist_pdf_data <- reactive({
  generate_dist_pdf(input$distributions)
})

sampling_dist_data <- reactive({
  generate_sample_dist(input$distributions, size=input$dist_sample_size, reps=input$dist_replications) |> 
    summarise(
      sample_mean = mean(x)
    )
})

output$propDistPlot <- renderPlot({
  
  samples() |> 
    ggplot(aes(x=prop_red)) +
    geom_histogram(fill="steelblue", colour="black", boundary=0.4, binwidth=0.05, alpha=0.7) +
    labs(
      x="Sample proportion of red balls",
      y="Count",
      title = "The distribution of sample proportions",
      subtitle = "How does the shape of the distribution change as the sample size and number of samples changes?"
    )
  
})

output$distPdfPlot <- renderPlot({
  
  dist_name <- names(which(distribution_options == input$distributions))
  
  dist_pdf_data() |> 
    ggplot(aes(x=x, y=y)) +
    geom_line(linewidth=1) +
    labs(
      x="x",
      y="Likelihood",
      title = str_glue("The {dist_name} distribution")
    )
  
})

output$sampleDistPlot <- renderPlot({
  dist_name <- names(which(distribution_options == input$distributions))
  sampling_dist_data() |> 
    ggplot(aes(x=sample_mean)) +
    geom_histogram(fill="steelblue", colour="black", alpha=0.7, bins=30) +
    labs(
      x="Sample mean",
      y="Count",
      title = str_glue("The distribution of sample means for {dist_name}"),
      subtitle = "How does the shape of the distribution change as the sample size and number of samples changes?"
    )
})

output$meanBox <- renderValueBox({
  box(
    round(mean(samples()$prop_red),4)
    # title = "Distribution mean"
  )
})

output$sdBox <- renderValueBox({
  box(
    round(sd(samples()$prop_red), 4)
    # title = "Distribution standard error"
  )
})
```

# Introduction 

## {height="35%"}

::: {.card title="Introduction to sampling distributions"}
**What is a sampling distribution?** After exploring the scenario below, you should have a good idea of what a sampling distribution is and how it changes based on the sampling procedure employed. You should understand how the number of samples take and the size of the samples affects the estimate of the mean and standard error of the population parameter being studied. You will also be able to explain the basic idea behind the **Central Limit Theorem** and get some hands on experience with the concept of **bootstrapping**. All set? Let's get started!

We often don't know the value of the population parameter that we're trying to study. To better understand the value of the parameter, we can either take a **census** or take one or more **samples**. A census involves making an observation of every individual in the population. This is often either impossible or prohibitively time consuming and expensive. This is why sampling is typically used to make an estimate of the parameter. When sampling, we take one or more samples of a given size from the population. In practice, a single sample is often taken and the sample size is a large as time and budget will allow.
:::

## {height="65%"}

::: {.card title="Important terms"}

**Sample** - A set of observations made on a subset of the population of interest. Measuring the length of 50 trout pulled from a lake, polling potential voters about a policy issue, and inspecting products on an assembly line at random for defects are all examples of sampling.

**Biased & random samples** - When samples are taken, each individual in the population from which samples are taken should have an equal chance of being included in the sample. This results in a *random* sample that is representative of the population. Summary statistics computed from such a sample can be generalized to the larger population. If certain individuals or groups of individuals within the population are more likely to be sampled than others, then the sample is said to be *biased*. Estimates made on a biased sample are more likely to incorrect. As a result, estimates biased samples do not generalize to the population.

**Sample statistic** - A summary statistic of a sample drawn from a population that estimates a population parameter of interest. It might be the mean height of college women basketball players or the proportion of voters who support a specific initiative.

**Sampling variance** - When drawing samples from a population, there will be some variability in the individual observations. This results in variation in the sample statistics computed from the samples.

**Sampling distribution** - When multiple samples are taken and the summary statistic of interest is computed, *sampling variation* will result in a distribution of values for the sample statistic.

**Standard error** - The standard error is simply the standard deviation of the sampling distribution.

:::

# Sampling Distributions

##

::: {.card title="A basic sampling scenario"}
In this scenario, we want to know what proportion of balls in a bowl are red. The bowl contains 2400 balls, so taking a census would be really tedious. There are different shovels that can be used to take samples and many samples can be taken. Whether sampling 25, 50, 75, or 100 balls at a time, it is unlikely that any two samples will have the same proportion of red balls. This is a demonstration of *sampling variance*. The degree of sampling variance in turn has an effect on the sampling distribution.

In the panel below, you can explore how the sampling distribution changes as the sample size and number of samples is increased or decreased. Experiment with different sample sizes and number of samples taken. How does the distribution change? What about the sampling distribution mean and standard error? What is a reasonable estimate for the proportion of red balls in the bowl?
:::

## {height="50%"}

```{r}
#| content: card-sidebar
#| width: 25%

sliderInput("sample_size", "Sample size:", 
            min = 25, max = 100, value = 50, step=25, ticks=FALSE, width="95%")
selectInput("replications", "Number of samples taken:", 
            choices=replicate_count, selected=replicate_count[2], width="95%")
```


```{r}
#| title: Sampling distribution visualization
plotOutput("propDistPlot")
```

## {height="15%"}

### {width="50%"}

::: {.valuebox icon="align-bottom" color="blue" title="Distribution mean"}
```{r}
valueBoxOutput("meanBox")
```
:::
### {width="50%"}
::: {.valuebox icon="bar-chart-line" color="blue" title="Distribution standard error"}
```{r}
valueBoxOutput("sdBox")
```
:::

# The Central Limit Theorem

## {height="30%"}

::: {.card title="What is the Central Limit Theorem?"}
The Central Limit Theorem is the pillar that much of classical statistics rests on. This theorem states that the statistics computed from repeatedly sampling from a population will be approximate normally distributed, *regardless of the underlying distribution of the population parameter*. The greater the number of samples, the better this approximation. This is an important result because it allows us to use the normal distribution's symmetry to construct things like *confidence intervals* that help us quantify the uncertainty of our population parameter estimates.

The form below allows you to see this for yourself. Experiment with sample size, number of samples, and the nature of the underlying distribution to see the Central Limit Theorem in action. In particular, notice the very different shapes of the underlying distributions that the samples are drawn from.
:::

## {height="70%"}

```{r}
#| content: card-sidebar
#| width: 25%

replicate_count <- c("10"=10,"100"=100,"500"=500,"1000"=1000)

selectInput("distributions", "Choose a distribution:", 
            choices=distribution_options, width="95%")
sliderInput("dist_sample_size", "Sample size:", 
            min = 25, max = 100, value = 50, step=25, ticks=FALSE, width="95%")
selectInput("dist_replications", "Number of samples taken:", 
            choices=replicate_count, selected=replicate_count[2], width="95%")
```

###

::: {.card title="The Central Limit Theorem in Action"}
```{r}
plotOutput("distPdfPlot")
plotOutput("sampleDistPlot")
```
:::

# Bootstrapping

## {height="30%"}

::: {.card title="What Bootstrapping?"}

:::

## {height="70%"}

::: {.card title="Sampling Distribution & Confidence Interval"}

:::